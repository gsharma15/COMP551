{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "c-UCqDhUp0eg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import string\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "SEED = 551"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "58XIua5eIB48",
    "outputId": "69187800-5500-45c6-c2b0-21ae3411923d"
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # Remove special characters\n",
    "    alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
    "    # Remove punctuations\n",
    "    punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x.lower())\n",
    "    # Remove white spaces\n",
    "    strip = lambda x: str.rsplit(x)\n",
    "    # Remove stopwords\n",
    "    remove_stopwords = lambda x: \" \".join([w for w in x if w not in stopwords.words('english')])\n",
    "    return text.map(alphanumeric).map(punc_lower).map(strip).map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s2InZwzuH9fj"
   },
   "outputs": [],
   "source": [
    "def cross_validation_split(total_instances, k=5):\n",
    "    fold_size = total_instances // k\n",
    "    # Get shuffled indices\n",
    "    inds = np.random.permutation(total_instances)\n",
    "\n",
    "    for f in range(k):\n",
    "        # Take the f'th fold to be validation data\n",
    "        validation_inds = inds[f * fold_size : (f+1) * fold_size]\n",
    "\n",
    "        # Take the remaining k - f folds to be testing data. Essentially\n",
    "        # this means take everything except validation_inds\n",
    "        train_inds = np.delete(inds, validation_inds)\n",
    "\n",
    "        yield validation_inds, train_inds\n",
    "\n",
    "\n",
    "# This is called for each hyperparameter combination we want to test\n",
    "def kfoldCV(all_training_data, all_training_labels, model, k=5):\n",
    "    total_instances = len(all_training_data)\n",
    "    accuracies = []\n",
    "    # For each fold, go through all\n",
    "    for fold, (val_inds, train_inds) in enumerate(cross_validation_split(total_instances, k)):\n",
    "        # Training\n",
    "        X_train = all_training_data[train_inds]\n",
    "        y_train = all_training_labels[train_inds]\n",
    "        # Validation\n",
    "        X_val = all_training_data[val_inds]\n",
    "        y_val = all_training_labels[val_inds]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_validation_labels = model.predict(X_val)\n",
    "        accuracy = evaluate_acc(pred_validation_labels, y_val)\n",
    "\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return np.sum(accuracies) / k\n",
    "\n",
    "\n",
    "def evaluate_acc(Predicted_label, True_label):\n",
    "    return np.sum(True_label == Predicted_label)/True_label.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaÃ¯ve Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "j0UIVPsQOZtp"
   },
   "outputs": [],
   "source": [
    "class MultinomialNB(object):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'Multinomial NB model with alpha = {self.alpha}'\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        count_sample = X.shape[0]\n",
    "        separated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "        self.class_log_prior_ = [np.log(len(i) / count_sample) for i in separated]\n",
    "        count = np.array([np.array(i).sum(axis=0) for i in separated]) + self.alpha\n",
    "        self.feature_log_prob_ = np.log(count / count.sum(axis=1)[np.newaxis].T)\n",
    "        return self\n",
    "\n",
    "    def predict_log_proba(self, X):       \n",
    "        return [(self.feature_log_prob_ * x).sum(axis=1) + self.class_log_prior_\n",
    "                for x in X]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_log_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.1, max_iter=100, C=0.1, regularization='l2',\n",
    "                 fit_intercept=True, multi_class=False, \n",
    "                 threshold = 0.5):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.theta = None\n",
    "        self.h = None\n",
    "        self.threshold = threshold\n",
    "        self.multi_class = multi_class\n",
    "        self.regularization = regularization\n",
    "        self.C = C\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'LR model with learning_rate = {self.learning_rate}, max_iter = {self.max_iter}, C = {self.C}, regularization = {self.regularization}, fit_intercept = {self.fit_intercept}, threshold = {self.threshold}'\n",
    "        \n",
    "    def _sigmoid(self, z):\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _softmax(self, z):\n",
    "        return np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "            \n",
    "    def _add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "        return X\n",
    "\n",
    "    def _gradient_descent(self, X, y):\n",
    "        if self.multi_class:\n",
    "            self.theta = np.zeros((X.shape[1], np.max(y)+1))\n",
    "            y_ohe = np.zeros((y.size, np.max(y)+1))\n",
    "            rows = np.arange(y.size)\n",
    "            y_ohe[rows, y] = 1            \n",
    "            bias = np.random.random(np.max(y)+1)\n",
    "            for i in range(self.max_iter):\n",
    "                z = X @ self.theta + bias\n",
    "                h = self._softmax(z)\n",
    "                if self.regularization == 'l2':\n",
    "                    w_grad = (1/y.size)*(self.C*np.matmul(X.T, (h - y_ohe))+np.sum(self.theta))    \n",
    "                elif self.regularization == 'l1':\n",
    "                    w_grad = (1/y.size)*(self.C*np.matmul(X.T, (h - y_ohe))) \n",
    "                b_grad = (1/y.size)*np.sum(h - y_ohe)\n",
    "                self.theta = self.theta - self.learning_rate * w_grad\n",
    "                bias = bias - self.learning_rate * b_grad\n",
    "        else:\n",
    "            self.theta = np.random.random(X.shape[1])\n",
    "            for i in range(self.epoch):\n",
    "                z = np.matmul(X, self.theta)\n",
    "                h = self._sigmoid(z)\n",
    "                gradient = np.dot(X.T, (h-y)) / y.size\n",
    "                self.theta = self.theta - (self.learning_rate * gradient)\n",
    "                \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self._add_intercept(X)\n",
    "        self._gradient_descent(X, y)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        assert self.theta is not None\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X = self._add_intercept(X)\n",
    "        \n",
    "        if self.multi_class:\n",
    "            return np.argmax(self._softmax(np.matmul(X, self.theta)), axis=1)\n",
    "        else:\n",
    "            return self._sigmoid(np.dot(X, self.theta))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.multi_class:\n",
    "            return self.predict_proba(X)\n",
    "        else:\n",
    "            return self.predict_proba(X) >= self.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 News Group Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "S9eHIZDYEiWm"
   },
   "outputs": [],
   "source": [
    "news_train = fetch_20newsgroups(subset='train',random_state=SEED, remove=('headers','footers','quotes'))\n",
    "news_test = fetch_20newsgroups(subset='test', random_state=SEED, remove=('headers','footers','quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6IKUovCxFwGI",
    "outputId": "ee68121c-62cc-460d-ced2-e74808e34f45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's also Billy Jack, The Wild One, Smokey ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nI didn't see any smilies in this message s...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nPlease, define cell church.  I missed it som...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\njust picked out this one point because it st...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n\\n\\nCan somebody reconcile the apparent co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target\n",
       "0  There's also Billy Jack, The Wild One, Smokey ...       8\n",
       "1  \\n\\nI didn't see any smilies in this message s...      10\n",
       "2  \\nPlease, define cell church.  I missed it som...      15\n",
       "3  \\njust picked out this one point because it st...      15\n",
       "4  \\n\\n\\n\\nCan somebody reconcile the apparent co...       0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({'data': news_train.data, 'target': news_train.target})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gB7PnMLjIExz",
    "outputId": "ec4d36a6-46ed-428d-9b77-5173a1dea49d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry about the garbage code, the following is...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From article &lt;1993May12.111030@IASTATE.EDU&gt;, b...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi \\n\\nI have heard about a linear mode for th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had a Valentine for about 9 months now an...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  target\n",
       "0  Sorry about the garbage code, the following is...       5\n",
       "1                                         \\n\\n\\n\\n\\n       3\n",
       "2  From article <1993May12.111030@IASTATE.EDU>, b...      17\n",
       "3  Hi \\n\\nI have heard about a linear mode for th...       3\n",
       "4  I've had a Valentine for about 9 months now an...       7"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'data': news_test.data, 'target': news_test.target})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with 20%, 40%, 60%, 80% data\n",
    "X_train, _, y_train, _ = train_test_split(train_df['data'], train_df['target'], test_size=0.8,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = text_preprocessing(train_df.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = text_preprocessing(test_df.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df.target.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6_TCR2bH6F0",
    "outputId": "488ae941-5aa4-45f6-dd77-3a2181acc64d"
   },
   "outputs": [],
   "source": [
    "# Use TF-IDF Vectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "vocab = vectorizer.vocabulary_\n",
    "vectorizer_1 = TfidfVectorizer(vocabulary=vocab)\n",
    "X_test = vectorizer_1.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bigrams and trigrams\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(stop_words='english', ngram_range=(3, 3)) # (2, 2) for bigrams\n",
    "# X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "# vocab = vectorizer.vocabulary_\n",
    "# vectorizer_1 = CountVectorizer(vocabulary=vocab)\n",
    "# X_test = vectorizer_1.fit_transform(test_df.data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning and results for the NaÃ¯ve Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnYFQwjCPshM",
    "outputId": "666f9aed-232a-44b7-e664-c9a0b2cefde0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy for Multinomial NB model with alpha = 0.5 is 0.86\n",
      "Average validation accuracy for Multinomial NB model with alpha = 1.0 is 0.84\n",
      "Average validation accuracy for Multinomial NB model with alpha = 1.5 is 0.82\n",
      "Average validation accuracy for Multinomial NB model with alpha = 2.0 is 0.81\n",
      "Best validation accuracy of 0.86\n"
     ]
    }
   ],
   "source": [
    "# Grid Search with cross validation for the best parameters for the dataset\n",
    "alphas = [0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "for alpha in alphas:\n",
    "    nb_model = MultinomialNB(alpha=alpha)\n",
    "    validation_acc = kfoldCV(X_train, y_train, nb_model, k=5)\n",
    "    print(f'Average validation accuracy for {nb_model} is {round(validation_acc, 2)}')\n",
    "    if validation_acc > best_accuracy:\n",
    "        best_accuracy = validation_acc\n",
    "        best_model = nb_model\n",
    "\n",
    "print(f'Best validation accuracy of {round(best_accuracy, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = kfoldCV(X_test, y_test, best_model, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set 0.8633\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on the test set {round(test_accuracy, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning and results for the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'regularization': ['l2'],\n",
    "    'C': [1, 0.5, 0.2],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'max_iter': [1, 5, 10],\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*params.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7729\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7729\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7732\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7725\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.771\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7728\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7714\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7712\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7714\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7735\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.771\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7637\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7706\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7713\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7728\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7709\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7715\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7743\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7707\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7708\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7698\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7729\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.769\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.767\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7738\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7718\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7713\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7714\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7703\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7737\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7724\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7714\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7723\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7709\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7738\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.7702\n",
      "Best validation accuracy of 0.77 found for LR model with learning_rate = 0.1, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "accuracies = []\n",
    "for e in experiments:\n",
    "    mlr = LogisticRegression(learning_rate=e['learning_rate'], max_iter=e['max_iter'], C=e['C'], \n",
    "                                  regularization=e['regularization'], fit_intercept=True, \n",
    "                                  multi_class=True, threshold = 0.5)\n",
    "    validation_acc = kfoldCV(X_train, y_train, mlr, k=5)\n",
    "    print(f'Average validation accuracy for {mlr} is {round(validation_acc, 4)}')\n",
    "    accuracies.append(validation_acc)\n",
    "    if validation_acc > best_accuracy:\n",
    "        best_accuracy = validation_acc\n",
    "        best_model = mlr\n",
    "    gc.collect()\n",
    "\n",
    "print(f'Best validation accuracy of {round(best_accuracy, 2)} found for {mlr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = kfoldCV(X_test, y_test, best_model, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set 0.7811\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on the test set {round(test_accuracy, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment140 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = ['sentiment', 'ids', 'date', 'flag', 'user', 'text']\n",
    "data = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', names=header_list)\n",
    "X = data.text\n",
    "y = data.sentiment\n",
    "# Reducing the data to 10% of original data\n",
    "X, _, y, _ = train_test_split(X, y, test_size=0.90,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with 20%, 40%, 60%, 80% data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.8,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = text_preprocessing(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For bigrams and trigrams\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(stop_words='english', ngram_range=(3, 3))\n",
    "# X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "# vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = ['sentiment', 'ids', 'date', 'flag', 'user', 'text']\n",
    "test_data = pd.read_csv('new_testdata.manual.2009.06.14.csv', encoding='latin-1', names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.text\n",
    "y_test = test_data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = text_preprocessing(X_test)\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_1 = TfidfVectorizer(vocabulary=vocab)\n",
    "X_test = vectorizer_1.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning and results for the NaÃ¯ve Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy for Multinomial NB model with alpha = 0.5 is 0.4\n",
      "Average validation accuracy for Multinomial NB model with alpha = 1.0 is 0.4\n",
      "Average validation accuracy for Multinomial NB model with alpha = 1.5 is 0.4\n",
      "Average validation accuracy for Multinomial NB model with alpha = 2.0 is 0.4\n",
      "Best validation accuracy of 0.4 found for Multinomial NB model with alpha = 1.0\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "for alpha in alphas:\n",
    "    nb_model = MultinomialNB(alpha=alpha)\n",
    "    validation_acc = kfoldCV(X_train, y_train, nb_model, k=5)\n",
    "    print(f'Average validation accuracy for {nb_model} is {round(validation_acc, 2)}')\n",
    "    if validation_acc > best_accuracy:\n",
    "        best_accuracy = validation_acc\n",
    "        best_model = nb_model\n",
    "\n",
    "print(f'Best validation accuracy of {round(best_accuracy, 2)} found for {best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = kfoldCV(X_test, y_test, best_model, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set 0.4479\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on the test set {round(test_accuracy, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning and results for the Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'regularization': ['l2'],\n",
    "    'C': [1, 0.5, 0.2],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'max_iter': [1, 5, 10],\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = zip(*params.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4008\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4005\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3992\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4005\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4006\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4004\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.401\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.401\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 1, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4001\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 5, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4001\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 10, C = 1, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4012\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3997\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3993\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4012\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4013\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4011\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4001\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4006\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3999\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3994\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 1, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3993\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 5, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3997\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 10, C = 0.5, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.402\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4001\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4002\n",
      "Average validation accuracy for LR model with learning_rate = 0.001, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4007\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4002\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3992\n",
      "Average validation accuracy for LR model with learning_rate = 0.01, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4008\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4003\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4015\n",
      "Average validation accuracy for LR model with learning_rate = 0.05, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4008\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 1, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.4009\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 5, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3997\n",
      "Average validation accuracy for LR model with learning_rate = 0.1, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5 is 0.3996\n",
      "Best validation accuracy of 0.4 found for LR model with learning_rate = 0.1, max_iter = 10, C = 0.2, regularization = l2, fit_intercept = True, threshold = 0.5\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "accuracies = []\n",
    "for e in experiments:\n",
    "    mlr = LogisticRegression(learning_rate=e['learning_rate'], max_iter=e['max_iter'], C=e['C'], \n",
    "                                  regularization=e['regularization'], fit_intercept=True, \n",
    "                                  multi_class=True, threshold = 0.5)\n",
    "    validation_acc = kfoldCV(X_train, y_train, mlr, k=5)\n",
    "    print(f'Average validation accuracy for {mlr} is {round(validation_acc, 4)}')\n",
    "    accuracies.append(validation_acc)\n",
    "    if validation_acc > best_accuracy:\n",
    "        best_accuracy = validation_acc\n",
    "        best_model = mlr\n",
    "    gc.collect()\n",
    "\n",
    "print(f'Best validation accuracy of {round(best_accuracy, 2)} found for {mlr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = kfoldCV(X_test, y_test, best_model, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set 0.8676\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy on the test set {round(test_accuracy, 4)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COMP551_MP2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
